{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  \n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, precision_score, recall_score\n",
    "import pandas\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pandas.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load, get_results, get_labels, transform_binary_probabilities, transform_binary_predictions, calculate_accuracy_loss, plot_confusion_matrix, plot_precision_recall, plot_roc_curve, calculate_pr_auc, calculate_confusion_matrix_stats, calculate_confusion_matrix, plot_tsne, accession_from_filename, plot_expert_confusion, plot_multiple_grad_cam, get_expert_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import describe, all_features, data, print_describe, load_single\n",
    "from run import characterize_data\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DIRECTORY = \"c3-c4-free/data\"\n",
    "MODEL_UUID = \"1b356a9e-126c-4f91-8f41-8d6baa4f79de\"\n",
    "MODEL_TYPE = \"v2\"\n",
    "SELECTIONS = \"None\"\n",
    "PARAMETERS_ID = \"parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTIONS = eval(SELECTIONS)\n",
    "FEATURES = \"{}/features.csv\".format(DIRECTORY)\n",
    "RAW = \"{}/raw\".format(DIRECTORY)\n",
    "TRAIN = \"{}/train\".format(DIRECTORY)\n",
    "VALIDATION = \"{}/validation\".format(DIRECTORY)\n",
    "MODEL = \"{}/models/{}-{}.h5\".format(config.OUTPUT, MODEL_UUID, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesion descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_describe(raw=RAW, features=FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, validation, _ = data(shuffle_train=False, validation_dir=VALIDATION, train_dir=TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training data breakdown: \", characterize_data(train))\n",
    "print(\"validation data breakdown: \", characterize_data(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(model, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = transform_binary_probabilities(results)\n",
    "predictions = transform_binary_predictions(results)\n",
    "labels = get_labels(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = calculate_accuracy_loss(model, validation)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(validation, results)\n",
    "fig.savefig(\"figures/{}-confusion-matrix.svg\".format(PARAMETERS_ID), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = calculate_confusion_matrix_stats(labels, results)\n",
    "pandas.DataFrame(stats, index=validation.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(labels, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC:\", roc_auc_score(labels, probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average precision:\", average_precision_score(labels, probabilities))\n",
    "print(\"Precision:\", precision_score(labels, predictions), \"Recall:\", recall_score(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(labels, results)\n",
    "fig.savefig(\"figures/{}-precision-recall.svg\".format(PARAMETERS_ID), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PR AUC:\", calculate_pr_auc(labels, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score:\", f1_score(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignancy, modality, category = all_features(features=FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_dataset = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_labels = [malignancy.get(accession_from_filename(f), \"unknown\") for f in tsne_dataset.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_tsne(model, \"dense_5\", tsne_dataset, tsne_labels, perplexity=5)\n",
    "fig.savefig(\"figures/{}-tsne.svg\".format(PARAMETERS_ID), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_1, fig = plot_expert_confusion(\"evaluations/radiology-9809.json\", validation)\n",
    "fig.savefig(\"figures/{}-confusion-matrix-expert-1.svg\".format(PARAMETERS_ID), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(expert_1, index=validation.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC with experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_roc_curve(labels, results, experts=[{ **expert_1, \"name\":\"expert 1\" }, { **expert_1, \"name\":\"expert 2\" }])\n",
    "fig.savefig(\"figures/{}-roc-curve.svg\".format(PARAMETERS_ID), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inv_indices = {v: k for k, v in validation.class_indices.items()}\n",
    "for k, v in SELECTIONS.items(): \n",
    "    display(HTML(\"<h5>diagnosis: {} | prediction: {}</h5>\".format(inv_indices[k[0]], inv_indices[k[1]])))\n",
    "    fig = plot_multiple_grad_cam(\n",
    "        [os.path.join(VALIDATION, image) for image in v], \n",
    "        model, \n",
    "        \"dense_6\", \n",
    "        penultimate_layer=\"res5c_branch2c\",\n",
    "        filter_idx=[0],\n",
    "    )\n",
    "    fig.savefig(\"figures/{}-grad-cam-{}-{}.png\".format(PARAMETERS_ID, inv_indices[k[0]], inv_indices[k[1]]), bbox_inches = \"tight\")\n",
    "    print(get_expert_results(\"evaluations/radiology-9809.json\", v, expert_key=\"malignantBenign\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
